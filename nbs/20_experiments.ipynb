{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class to retrieve comet experiment data.\n",
    "output-file: experiments.html\n",
    "title: Experiments class\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, json, csv\n",
    "from comet_ml import API, APIExperiment, start\n",
    "from pct.hierarchy import PCTHierarchy  \n",
    "from comet_ml.query import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CometExperimentManager:\n",
    "    def __init__(self, api_key: str = None, workspace: str = None):\n",
    "        self.api = API(api_key)\n",
    "        self.workspace = workspace\n",
    "\n",
    "    def get_all_artifacts_indexed(self):\n",
    "        \"\"\"Retrieve all artifacts and sort them by source experiment key. Updates existing cache with new artifacts.\"\"\"\n",
    "        filename = '/tmp/artifacts/artifacts_results.json'\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        # Load existing results if file exists\n",
    "        existing_results = {}\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as file:\n",
    "                existing_results = json.load(file)\n",
    "        \n",
    "        # Get all current artifacts from API\n",
    "        artifacts = self.api.get_artifact_list(workspace=self.workspace)\n",
    "        experiment = start(workspace=self.workspace)\n",
    "        \n",
    "        # Get current artifact names from API\n",
    "        current_artifact_names = {artifact_dict['name'] for artifact_dict in artifacts['artifacts']}\n",
    "        \n",
    "        # Get existing artifact names from our cache\n",
    "        existing_artifact_names = set(existing_results.values())\n",
    "        \n",
    "        # Find new artifacts that aren't in our cache\n",
    "        new_artifact_names = current_artifact_names - existing_artifact_names\n",
    "        \n",
    "        results = existing_results.copy()  # Start with existing results\n",
    "        \n",
    "        # Process only new artifacts\n",
    "        for artifact_dict in artifacts['artifacts']:\n",
    "            artifact_name = artifact_dict['name']\n",
    "            if artifact_name in new_artifact_names:\n",
    "                try:\n",
    "                    logged_artifact = experiment.get_artifact(artifact_name)\n",
    "                    print(f\"Adding new artifact: {logged_artifact.source_experiment_key} -> {artifact_name}\")\n",
    "                    results[logged_artifact.source_experiment_key] = artifact_name\n",
    "                except Exception as e:\n",
    "                    print(f\"Error retrieving artifact {artifact_name}: {e}\")\n",
    "\n",
    "        # Save updated results to file\n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "        experiment.end()\n",
    "        \n",
    "        if new_artifact_names:\n",
    "            print(f\"Added {len(new_artifact_names)} new artifacts to cache\")\n",
    "        else:\n",
    "            print(\"No new artifacts found\")\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def get_experiments_by_metrics(self, project_name: str = None, score_threshold: float = None, reward_threshold: float = None, max : bool = False):\n",
    "        \"\"\"\n",
    "        Retrieve experiments for a project where the metric 'score' is less than\n",
    "        score_threshold and 'reward_avg' is greater than or equal to reward_threshold.\n",
    "        \"\"\"\n",
    "        if max:\n",
    "            experiments = self.api.query(self.workspace, project_name, \n",
    "                                       (Metric(\"score\") > score_threshold) & \n",
    "                                       (Metric(\"reward_avg\") > reward_threshold))\n",
    "        else:\n",
    "            experiments = self.api.query(self.workspace, project_name, \n",
    "                                       (Metric(\"score\") < score_threshold) & \n",
    "                                       (Metric(\"reward_avg\") > reward_threshold))\n",
    " \n",
    "        return experiments\n",
    "\n",
    "    def get_artifact_name(self, experiment: APIExperiment = None):\n",
    "        \"\"\"Retrieve the name of an artifact from an experiment.\"\"\"\n",
    "        artifacts = experiment.get_artifacts()\n",
    "        return artifacts[0]['artifact_name'] if artifacts else None\n",
    "\n",
    "    def download_and_run_artifact(self, artifact_name: str = None, seeds: list[int] = None):\n",
    "        \"\"\"\n",
    "        Download an artifact to '/tmp/artifacts/' and run PCTHierarchy.run_from_file\n",
    "        with the artifact filename, returning the score value for each run.\n",
    "        \"\"\"\n",
    "        download_path = f\"/tmp/artifacts/\"\n",
    "        os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    " \n",
    "        full_path = os.path.join(download_path, artifact_name)\n",
    "        if os.path.exists(full_path):\n",
    "            pass\n",
    "        else:\n",
    "            experiment = start(workspace=self.workspace)\n",
    "            logged_artifact  = experiment.get_artifact(artifact_name)\n",
    "            # print(logged_artifact.source_experiment_key)\n",
    "            # local_artifact = logged_artifact.download(download_path)\n",
    "            logged_artifact.download(download_path)\n",
    "            # filename = f\"{local_artifact.download_local_path}{artifact_name}\"\n",
    "            experiment.end()\n",
    "    \n",
    "        rewards = []\n",
    "        for seed in seeds:\n",
    "            hierarchy, score = PCTHierarchy.run_from_file(full_path, seed=seed)\n",
    "            metrics = hierarchy.get_environment().get_metrics()\n",
    "            # print(f'Score={score:0.3f} {metrics}')\n",
    "            rewards.append(metrics['reward'])\n",
    "\n",
    "\n",
    "\n",
    "        return rewards\n",
    "\n",
    "    def get_original_metrics(self, experiment: APIExperiment = None):\n",
    "        \"\"\"Retrieve the metrics for an experiment.\"\"\"\n",
    "        metrics = {}\n",
    "        metrics['score'] = eval(experiment.get_metrics(\"score\")[0]['metricValue'])\n",
    "        hyperparameters = experiment.get_parameters_summary()\n",
    "\n",
    "        for param in hyperparameters:\n",
    "            if param['name'] == 'mode':\n",
    "                metrics['mode'] = param['valueCurrent']\n",
    "                break\n",
    "\n",
    "        metrics['name'] = experiment.name\n",
    "        return metrics\n",
    "\n",
    "    def run_experiments_and_record_results(self, project_name: str = None, experiments: list[APIExperiment] = None, artifact_results: dict = None, num_runs: int = 0, output_csv: str = None):\n",
    "        \"\"\"\n",
    "        Run each experiment for a given project a specified number of times and record the score and the\n",
    "        number of times the reward is 100, -100, or something else. Save results to a CSV file.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for experiment in experiments:\n",
    "            try:\n",
    "                artifact_name = artifact_results[experiment.id]\n",
    "            except KeyError:\n",
    "                print(f\"WARNING: Artifact not found for experiment {experiment.id}\")\n",
    "                continue\n",
    "\n",
    "            metrics = self.get_original_metrics(experiment)\n",
    "\n",
    "            print(f\"Running experiment {experiment.id} in project {project_name} with artifact {artifact_name}\")\n",
    "            if not artifact_name:\n",
    "                continue\n",
    "\n",
    "            rewards = self.download_and_run_artifact(artifact_name, seeds=range(num_runs))\n",
    "            reward_counts = {'100': 0, '-100': 0, 'other': 0}\n",
    "\n",
    "            for reward in rewards:\n",
    "                if reward == 100:\n",
    "                    reward_counts['100'] += 1\n",
    "                elif reward == -100:\n",
    "                    reward_counts['-100'] += 1\n",
    "                else:\n",
    "                    reward_counts['other'] += 1\n",
    "            print(f\"Rewards: {reward_counts}\")\n",
    "            results.append({\n",
    "                'name': metrics['name'],\n",
    "                'score': round(metrics['score'], 5),\n",
    "                'mode': metrics['mode'],\n",
    "                'reward_100': reward_counts['100'],\n",
    "                'reward_-100': reward_counts['-100'],\n",
    "                'reward_other': reward_counts['other'],\n",
    "                'experiment_key': '/'.join((\"https://www.comet.com\", self.workspace, project_name, experiment.id)),\n",
    "                'artifact_name': artifact_name\n",
    "            })\n",
    "        # Sort results by 'reward_100' in descending order, then by 'reward_other' in descending order\n",
    "        results.sort(key=lambda x: (-x['reward_100'], -x['reward_other']))\n",
    "        \n",
    "        # Only save results to CSV if there are actually results\n",
    "        if results:\n",
    "            with open(output_csv, mode='w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=['name', 'score', 'mode', 'reward_100', 'reward_-100', 'reward_other', 'experiment_key', 'artifact_name'])\n",
    "                writer.writeheader()\n",
    "                writer.writerows(results)\n",
    "            print(f\"Saved {len(results)} results to {output_csv}\")\n",
    "        else:\n",
    "            print(\"No results to save - CSV file not created\")\n",
    "\n",
    "    def get_workspace_projects(self):\n",
    "        \"\"\"\n",
    "        Get all projects from the current workspace.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of project names in the workspace\n",
    "        \"\"\"\n",
    "        api = API()\n",
    "        projects = api.get_projects(workspace=self.workspace)\n",
    "        return projects\n",
    "        # return [project['name'] for project in projects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lunarlandercontinuous-v2/general/01e2d222f6d44c56b93a45c409dbf07a\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lunarlandercontinuous-v2/general/01e2d222f6d44c56b93a45c409dbf07a\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving artifact ga-000.238-s002-3x1-m000-LL0001-d9aaf2358a62b99f9bbd6e7db60e631d.properties: Artifact {'consumer_experiment_key': '01e2d222f6d44c56b93a45c409dbf07a', 'experiment_key': '01e2d222f6d44c56b93a45c409dbf07a', 'name': 'ga-000.238-s002-3x1-m000-LL0001-d9aaf2358a62b99f9bbd6e7db60e631d.properties', 'version_or_alias': None, 'workspace': None} is not in a finalized state and cannot be accessed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : only_bee_5002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lunarlandercontinuous-v2/general/01e2d222f6d44c56b93a45c409dbf07a\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : only_bee_5002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lunarlandercontinuous-v2/general/01e2d222f6d44c56b93a45c409dbf07a\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (1.90 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (1.90 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 861.60 KB/1.06 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 861.60 KB/1.06 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m no such metrics: 'reward_avg'; ignoring query, returning no matches\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m no such metrics: 'reward_avg'; ignoring query, returning no matches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 new artifacts to cache\n",
      "Filtered experiments: []\n"
     ]
    }
   ],
   "source": [
    "#|gui\n",
    "# Initialize the manager\n",
    "workspace = 'lunarlandercontinuous-v2'\n",
    "project_name = 'refinputs-smooth'\n",
    "manager = CometExperimentManager(workspace=workspace)\n",
    "\n",
    "# Test get_all_artifacts_sorted\n",
    "artifact_results = manager.get_all_artifacts_indexed()\n",
    "# print(\"Artifacts sorted by source experiment key:\", artifacts)\n",
    "\n",
    "# Test get_experiments_by_metrics\n",
    "experiments = manager.get_experiments_by_metrics(project_name=project_name, score_threshold=0.05, reward_threshold=10.0)\n",
    "print(\"Filtered experiments:\", experiments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|gui\n",
    "# import random\n",
    "\n",
    "# Test run_experiments_and_record_results\n",
    "if experiments:\n",
    "    output_csv = \"/tmp/artifacts/experiment_results.csv\"\n",
    "    manager.run_experiments_and_record_results(experiments=experiments, project_name=project_name, artifact_results=artifact_results, num_runs=2, output_csv=output_csv)\n",
    "    print(f\"Results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
