{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class to retrieve comet experiment data.\n",
    "output-file: experiments.html\n",
    "title: Experiments class\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import csv\n",
    "from comet_ml import API, APIExperiment\n",
    "from pct.hierarchy import PCTHierarchy  # Assuming PCTHierarchy is defined elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class CometExperimentManager:\n",
    "    def __init__(self, api_key: str, workspace: str):\n",
    "        self.api = API(api_key)\n",
    "        self.workspace = workspace\n",
    "\n",
    "    def get_all_artifacts_sorted(self):\n",
    "        \"\"\"Retrieve all artifacts and sort them by source experiment key.\"\"\"\n",
    "        artifacts = self.api.get_artifacts(workspace=self.workspace)\n",
    "        return sorted(artifacts, key=lambda artifact: artifact['source_experiment_key'])\n",
    "\n",
    "    def get_experiments_by_metrics(self, project_name: str, score_threshold: float, reward_threshold: float):\n",
    "        \"\"\"\n",
    "        Retrieve experiments for a project where the metric 'score' is less than\n",
    "        score_threshold and 'reward' is greater than or equal to reward_threshold.\n",
    "        \"\"\"\n",
    "        experiments = self.api.get(project_name=project_name, workspace=self.workspace)\n",
    "        filtered_experiments = [\n",
    "            exp for exp in experiments\n",
    "            if exp.get_metrics_summary('score') < score_threshold and\n",
    "               exp.get_metrics_summary('reward') >= reward_threshold\n",
    "        ]\n",
    "        return filtered_experiments\n",
    "\n",
    "    def get_artifact_name(self, experiment: APIExperiment):\n",
    "        \"\"\"Retrieve the name of an artifact from an experiment.\"\"\"\n",
    "        artifacts = experiment.get_artifacts()\n",
    "        return artifacts[0]['artifact_name'] if artifacts else None\n",
    "\n",
    "    def download_and_run_artifact(self, artifact_name: str, num_runs: int, seeds: list[int]):\n",
    "        \"\"\"\n",
    "        Download an artifact to '/tmp/artifacts/' and run PCTHierarchy.run_from_file\n",
    "        with the artifact filename, returning the score value for each run.\n",
    "        \"\"\"\n",
    "        artifact_path = f\"/tmp/artifacts/{artifact_name}\"\n",
    "        os.makedirs(os.path.dirname(artifact_path), exist_ok=True)\n",
    "        self.api.download_artifact(artifact_name, artifact_path)\n",
    "\n",
    "        scores = []\n",
    "        for seed in seeds:\n",
    "            score = PCTHierarchy.run_from_file(artifact_path, seed=seed)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def run_experiments_and_record_results(self, experiments: list[APIExperiment], num_runs: int, output_csv: str):\n",
    "        \"\"\"\n",
    "        Run each experiment a given number of times and record the score and the\n",
    "        number of times the reward is 100, -100, or something else. Save results to a CSV file.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for experiment in experiments:\n",
    "            artifact_name = self.get_artifact_name(experiment)\n",
    "            if not artifact_name:\n",
    "                continue\n",
    "\n",
    "            scores = self.download_and_run_artifact(artifact_name, num_runs, seeds=range(num_runs))\n",
    "            reward_counts = {'100': 0, '-100': 0, 'other': 0}\n",
    "\n",
    "            for score in scores:\n",
    "                if score == 100:\n",
    "                    reward_counts['100'] += 1\n",
    "                elif score == -100:\n",
    "                    reward_counts['-100'] += 1\n",
    "                else:\n",
    "                    reward_counts['other'] += 1\n",
    "\n",
    "            results.append({\n",
    "                'experiment_key': experiment.id,\n",
    "                'artifact_name': artifact_name,\n",
    "                'scores': scores,\n",
    "                'reward_100': reward_counts['100'],\n",
    "                'reward_-100': reward_counts['-100'],\n",
    "                'reward_other': reward_counts['other']\n",
    "            })\n",
    "\n",
    "        # Save results to CSV\n",
    "        with open(output_csv, mode='w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=['experiment_key', 'artifact_name', 'scores', 'reward_100', 'reward_-100', 'reward_other'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
